\documentclass[12pt]{article}
%------------------------------Packages généraux------------------------------

\usepackage[french]{babel}
\usepackage[T1]{fontenc}
\usepackage{ae}
\usepackage[utf8]{inputenc}
\usepackage{lmodern}
\usepackage[a4paper,left=2.5cm,right=2.5cm,top=2cm,bottom=3cm]{geometry}
%------------------------------Mathématiques------------------------------

\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{amsthm}
\usepackage{amsfonts}
\usepackage{eucal}
\usepackage{array}


%------------------------------Graphics------------------------------

\usepackage{caption}
\usepackage{subcaption}
\usepackage{graphicx}
\usepackage{fancyhdr}
\usepackage{fancybox}
\usepackage{color}
\usepackage{epstopdf}
\usepackage{float}
\usepackage{diagbox}
\usepackage{framed}

%------------------------------Syntaxe------------------------------

\usepackage{listings}
\usepackage{color} %red, green, blue, yellow, cyan, magenta, black, white
\definecolor{mygreen}{RGB}{28,172,0} % color values Red, Green, Blue
\definecolor{mylilas}{RGB}{170,55,241}
\lstloadlanguages{Matlab}

\def\refmark#1{\hbox{$^{\ref{#1}}$}}
\DeclareSymbolFont{cmmathcal}{OMS}{cmsy}{m}{n} %Mathcal correcte
\DeclareSymbolFontAlphabet{\mathcal}{cmmathcal}

\setlength{\parskip}{1ex plus 0.5ex minus 0.2ex}
\newcommand{\hsp}{\hspace{20pt}}
\newcommand{\HRule}{\rule{\linewidth}{0.5mm}}




\begin{document} 


\begin{titlepage}


  \begin{sffamily}
  \begin{center}

   
    \textsc{\Large Université de Liège}\\[0.8cm]
    
    \begin{figure}[h!]
		\begin{center}
		\includegraphics[scale=1.2]{logoULG}\\[1cm]
		\end{center}
	\end{figure}
	

    \textsc{\Large Eléments de processus stochastiques}\\[1.1cm]

    
    \HRule \\[0.4cm]
    { \LARGE \bfseries Méthodes de Monte Carlo par chaines de Markov - application à la cryptanalyse \\[0.4cm] }

    \HRule \\[0.5cm]
    
    \textsc{3\up{ème} bachelier en ingénieur civil} \\[2.5cm]

   \begin{minipage}{0.4\textwidth}
      \begin{flushleft} \large
        \emph{Auteurs:}\\
        Tom \textsc{Crasset} \\
        Antoine \textsc{Louis}  \\
        Romain \textsc{Vaneukem} \\
      \end{flushleft}
    \end{minipage}
    \begin{minipage}{0.4\textwidth}
      \begin{flushright} \large
        \emph{Professeur :}\\
        V. \textsc{Denoël}\\[0.5cm]
      
        \emph{Assistant:}\\
        L. \textsc{Duchesne}\\
        
      \end{flushright}
    \end{minipage}

    \vfill
    
    {\large Année académique 2017-2018}

  \end{center}
  \end{sffamily}
\end{titlepage}


\section{Chaînes de Markov pour la modélisation du langage et MCMC}
\subsection{Chaîne de Markov pour la modélisation du langage}

\subsubsection*{Question 1}
La méthode de vraisemblance a pour but de trouver la valeur du paramètre $\theta$ qui maximise la probabilité de trouver l'échantillon $ D_n$ qui ici est la séquence donnée par \texttt{seq1}. D'un point de vue théorique, nous avons
$$  \hat{\theta}_{MV} = arg(max_{\substack{\theta}} \mathcal{L}(\chi_i ,\theta))$$ avec $$ \mathcal{L}(\chi_i,\theta) = P(D_n \mid \theta) = P((\chi_1, ..., \chi_n) = (x_1, ..., x_n)) $$

Les événements étant indépendants, on a
$$ \mathcal{L}(\chi_i,\theta) = P((\chi_1 = x_1), ..., (\chi_2 = x_n)) = \prod_i P(\chi_i = x_i) $$

Pour trouver la matrice de transition par cette méthode, nous nous basons sur la séquence fournie. Prenons l'exemple de l'élément $\textbf{Q}(2,3)$ qui représente la probabilité de passer de la lettre 'b' à la lettre 'c'. Nous cherchons le nombre total des séquences 'bc' et divisons ce total par le nombre de 'b', ceci nous donnes bien la probabilité recherchée. Cette même méthode peut être appliquée pour la distribution initiale $\pi_0$. Ici, la fréquence d'une lettre est directement divisée par le nombre de lettres et on obtient ainsi la distribution recherchée.
\paragraph{}Voici les résultats numériques,
$$ \textbf{Q}=\begin{bmatrix}
0 & 0.0857 & 0.1 & 0.8143
\\1 & 0 &0 &0
\\0.6744 &0 &0 &0.3256
\\0.3662 & 0.1268 &0.507 &0
\end{bmatrix}$$
% Partie qui peut être tronquée si on dépasse la longueur de page
On remarquera de cette matrice quelques éléments intéressants. La diagonale est nulle, c'est-à-dire que la probabilité qu'une séquence ait deux fois la même lettre qui se suit est nulle. Chaque élément nul de cette matrice montre un événement impossible, il est donc impossible que la lettre "b" précèdent la lettre "c". Il y a une probabilité certaine que la "b" sera suivie par la lettre "a" car $ \textbf{Q}(2,1) = 1$.

Pour la distribution de probabilité initiale, nous obtenons
$$\pi_0 = \left(\begin{array}{c}0.355\\ 0.075\\ 0.215\\ 0.355 \end{array}\right)$$
Nous pouvons voir à la Figure \ref{etatChaineMarkov}, le diagramme d'états de la chaîne de Markov.
\begin{figure}[H]
\begin{framed}
      \centering
      \includegraphics[scale=0.23]{DiagrammeetatdeChaine.eps}
       \caption{Diagramme d'états de la chaîne de Markov}
       \label{etatChaineMarkov}
  \end{framed}
  \end{figure}
  
\subsubsection*{Question 2}
Maintenant que la matrice de transition a pu être calculée, il nous est possible de réaliser quelques opérations sur celle-ci. Dans un premier temps, nous supposons que la première lettre est choisie aléatoirement, cela correspond à une distribution de probabilité initiale uniforme: $\pi_0 = \begin{bmatrix}
0.25 & 0.25 & 0.25 & 0.25
\end{bmatrix}$. Pour obtenir les probabilité successive $P(X_t = i)$, il suffit de multiplier chaque densité par la matrice de transition.Cela revient à effectuer
$$ \pi_{n+1} = \pi_n \times \textbf{Q}\ $$
pour $n$ allant de $0$ à $t-1$. Graphiquement, nous obtenons le résultat suivant de la Figure \ref{ProbgraphBegin_random} ci-dessous

 \begin{figure}[H]
      \centering
      \includegraphics[scale=0.8]{uniformDist.eps}
       \caption{Représentation graphique de $P(X_t = i)$ avec i = 'a','b','c','d' partant d'une lettre aléatoire}
       \label{ProbgraphBegin_random}

  \end{figure}
 
Il nous est aussi demandé de représenter cette probabilité $P(X_t = i)$  en commençant par la lettre 'c'. La différence ici est la distribution de probabilité initiale: 
$\pi_0 = \begin{bmatrix}
0 & 0 & 1 & 0
\end{bmatrix}$
. Le graphique résultant peut être observé à la Figure \ref{ProbgraphBegin_c}.


 \begin{figure}[H]
      \centering
      \includegraphics[scale=0.8]{startOnC.eps}
       \caption{Représentation graphique de $P(X_t = i)$ avec i = 'a','b','c','d' partant de la lettre 'c'}
       \label{ProbgraphBegin_c}

  \end{figure} 
 
 
Par rapport à la théorie, la matrice $\textbf{Q}$ permet de passer d'un état à un autre. C'est-à-dire la probabilité conditionnelle, $$Q_n(i,j) = P(\chi_{n+1} = j|\chi_n = i_n)$$
A partir de la distribution initiale et de la matrice de transition, on peut caractériser entièrement la fonction de probabilité conjointe de la chaîne de Markov. En effet, par définition, on a
$$P(\chi_1 = i_1,X_0 = i_0) = P(X_1 = i_1|X_0 = i_0)P(\chi_0 = i_0)$$
On peut aussi s’intéresser à la fonction de probabilité conjointe entre les trois premières lettres.
$$P(\chi_2 = i_2,\chi_1 = i_1,\chi_0 = i_0) = P(\chi_2 = i_2|\chi_1 = i_1,\chi_0 = i_0)P(\chi_1 = i_1,\chi_0 = i_0)$$
Par définition d'une chaîne de Markov, un événement $n$ vers un événement $n+1$ ne dépend pas de l'historique. Alors,
$$P(\chi_2 = i_2,\chi_1 = i_1,\chi_0 = i_0) = P(\chi_2 = i_2|\chi_1 = i_1,)Q(i_1,i_0)\pi_0 = Q(i_1,i_2)Q(i_0,i_1)\pi_0$$
Et par récurrence,
$$P(\chi_n = i_n, ..., \chi_0 = i_0) = \pi_0 \prod_{k=1}^n Q(i_{k-1},i_k)$$
On peut observer que dans les évolutions représentées ici, les valeurs tendent, lorsque $t$ devient de plus en plus grand, vers une distribution déterministe. Lorsque $t$ tend vers l’infini, nous obtenons la distribution de probabilité stationnaire. Celle-ci sera étudiée plus en détails dans la question suivante.
 
\subsubsection*{Question 3}
Nous allons trouver la distribution de probabilité stationnaire par application directe de sa définition, c'est-à-dire
$$ [\pi_{\infty}]_j =  \lim_{t \rightarrow \infty} P(\chi_t = j)$$
En pratique, il est question de trouver un $t$ suffisamment grand pour quitter la période transitoire. Nous pouvons le vérifier graphiquement à l'aide de la Figure \ref{stationaryperiod}.

% Le graphique Ci dessous n'est pas obligatoire si on excède la taille de projet (!Texte a modifier, si supprimer)

 \begin{figure}[H]
      \centering
      \includegraphics[scale=0.8]{stationnarity.eps}
       \caption{Représentation graphique de la période stationnaire}
       \label{stationaryperiod}
  \end{figure}
On peut observer qu'un $t$ allant jusqu’à 20 est suffisant pour atteindre la stationnarité avec une distribution initiale uniforme. On obtiens,
$$ \pi_{\infty} =   \begin{bmatrix}
0.3517 & 0.0754 & 0.2161 & 0.3568
\end{bmatrix}$$

\subsubsection*{Question 4}
Ils nous est demandé ici de générer une chaîne de Markov en démarrant d'une lettre choisie selon la distribution stationnaire. Chaque lettre est ensuite choisie aléatoirement selon la matrice de transition. Par exemple, si nous nous trouvons à la lettre 'a', la lettre suivante est choisie selon les probabilités: $P(\chi = a) = 0, ~P(\chi = b) = 0.0857,~ P(\chi = c) = 0.1,~ P(\chi = d) = 0.8143$.

Voici un exemple de réalisation pour une longueur de chaîne de 20:
\begin{center}
'\texttt{dcacadcadcacadbabadadcadadcada}'
\end{center}


On peut analyser la distribution de probabilité de cette chaîne générée avec la distribution stationnaire en regardant la fréquence de chaque lettre et en la divisant par la longueur de chaîne totale.

Les résultats en fonction de la longueur de chaîne sont disponibles à la Table \ref{chainProbaDistrib}. 
\begin{table}[H]
\centering
\label{my-label}
\begin{tabular}{|l||l|l|l|l|l|l|l||l|}
\hline
 $T$& $P(\chi = a)$&$ P(\chi = b)$  & $ P(\chi = c)$ & $ P(\chi = d)$ \\ \hline \hline
20 &0.3&0.05&0.2&0.45\\ \hline
50 &0.34&0.08&0.22&0.36  \\ \hline
100 &0.37&0.11&0.18&0.34  \\ \hline
170 &0.3706&0.1&0.1765&0.3529  \\ \hline
230&0.3435&0.0609&0.2478&0.3478  \\ \hline
600 &0.3517&0.0733&0.2217&0.3533  \\ \hline \hline
$\pi_{\infty}$&0.3517&0.0754&0.2161&0.3568  \\ \hline
\end{tabular}
\caption{Distribution de probabilités des chaînes générées, où $T$ est la longueur de chaîne}
\label{chainProbaDistrib}
\end{table}

La distribution de probabilité stationnaire a été rappelée pour permettre une comparaison plus aisée. On peut observer que les valeurs de la distribution de probabilités de la chaîne générée se rapproche de plus en plus de la distribution stationnaire de la chaîne qui nous a été donnée. La différence est d'autant plus petite que $T$ est élevée et on voit qu'a partir de 600 lettres les valeurs sont relativement proches.

\subsubsection*{Question 5}
Lors de cette expérience, nous sommes partis d'une séquence donnée et nous avons étudié sa répartition dans le but de pouvoir simuler une chaîne similaire. 
La méthode de vraisemblance nous a permis de caractériser la séquence donnée et de définir sa représentation probabiliste. A partir de cette représentation, il nous a été possible de générer une séquence similaire.
% Cette figure n'est pas totalement obligatoire si on est out de place 
\begin{figure}[H]
\begin{framed}
      \centering
      \includegraphics[scale=0.18]{DiaTheo.eps}
       \caption{Deux représentations équivalentes du processus aléatoire}
       \label{ProcessDia}
  \end{framed}
  \end{figure}
  
Nous pouvons observer à la Figure \ref{ProcessDia} la démarche suivie lors des questions précédentes. C'est alors que l'on a pu observé à la question 4 le résultat convergent vers la distribution stationnaire de la matrice \textbf{Q} de départ. A une chaines de Markov, nous pouvons attribué deux représentation; une représentation statistique et une représentation probabilistique. C'est deux représentations sont interchangeables ce qui est représenté à la fiqure \label{ProcessDia}. Lors des questions précédentes nous sommes parti d'une représentation statistiques, la chaine initial, pour en déterminez la matrice de transitions et la distribution de probabilités initial et de là nous avons simulé une chaine similaires et le passages par la représentations statistqiues. De ces expériences, nous avons pu tirer les similitudes de ces deux approches.

\subsection{Algorithme MCMC}
\subsubsection*{Question 1}

Tout d'abord, nous savons qu'une distribution de probabilités est dite stationnaire lorsque 
\begin{equation}
\pi_{stat} = \pi_{stat}Q
\label{generalbalance}
\end{equation}
, appelée l'équation de balance générale. \\



Soit $S = \{1,..,N\}$  un espace d'état discret.
Une chaîne de Markov avec une distribution de probabilités initiale $\pi$ de S et de matrice de transition Q sur S est dite réversible si elle satisfait
\begin{equation}
\pi(i)Q_{ij} = \pi(j)Q_{ji} \qquad ,\forall i,j \in S
\label{detailedbalance}
\end{equation}
, où $Q_{ij}$ est la probabilité que la chaîne se déplace à l'état $j$ en partant de l'état $i$. Les équations \ref{detailedbalance} sont appelées équations de balance détaillée. \\

Si une chaîne de Markov est construite de manière à être réversible, alors il suit immédiatement de (\ref{detailedbalance}) que $\pi$ sera son unique distribution stationnaire unique. Il est beaucoup plus facile de prouver que les équations de balance détaillé (\ref{detailedbalance})  sont d'application que de prouver l'équation générale de balance (\ref{generalbalance}). \\

Si pour $\forall i,j \in S$, les équations de balances (\ref{detailedbalance}) sont satisfaites alors $\pi$ est une distribution stationnaire de Q. Si nous repartons de cette dernière égalité et sommons les deux membres, on obtient

\begin{equation}
\begin{split}
\sum_i{\pi(i)Q_{ij}} & = \sum_i{\pi(j)Q_{ji}} \\
& = \pi(j) \sum_i{Q_{ji}} \\
& = \pi(j) \qquad ~~~~~~~~~~,\forall i,j \in \{1,..,N\}
\end{split}
\label{eq2}
\end{equation}
ce qui prouve la stationnarité de notre distribution initiale.\\

Pour conclure, la distribution initiale de la chaîne de Markov est unique si la chaîne est irréductible, c'est-à-dire si la probabilité d’atteindre l’état $i$ partant de $j$ est non nulle. On voit dans notre fichier \texttt{Q.mat} que certaines lettres ne pourrons jamais immédiatement suivre une autre, mais cela ne veut pas dire qu'elles ne seront jamais accessibles.
Ainsi, on peut dire que notre chaîne de Markov est irréductible et donc notre distribution unique.













\subsubsection*{Question 2}
Le principe majeur derrière les chaines de Markov Monte Carlo est le fait que n'importe qu'elle chaine de Markov à état finit discret étant apériodique et irréductible a distribution stationnaire unique va converger vers la distribution stationnaire à l'infini.
The
main principle behind the Markov Chain Monte Carlo method is that any
Markov chain on a finite state space which is aperiodic and irreducible has
a unique stationary distribution, and that the k -step transition matrix P k will
%!!!!!!!!!!!!!!!!!!!!!!!NE REPOND PAS VRAIMENT A LA QUESTION (BON DEBUT)!!!!!!!!!!!!!!!!!!!!!!!!!
Soient 
$$Q_{ij} = q(i,j) \alpha(i,j)~~~~~~~~~\forall~ i \neq j$$
$$Q_{ii} = 1 - \sum Q_{ij}~~~~~~~~~~~\forall~ i \neq j$$
où $Q_{ij}$ est la matrice de transition, $q(i,j)$ la distribution de proposition et $\alpha(i,j)$ la probabilité d'acceptation telle que
$$\alpha(i,j) = \frac{s(i,j)}{1+t(i,j)}$$
où $s(i,j)$ est une fonction symétrique de i et j choisie de telle façon que pour tout i et j, $0 \leq \alpha(i,j) \leq 1$ et
$$t(i,j) = \frac{\pi(i) q(i,j)}{\pi(j) q(j,i)}$$
Dans ce cas, montrons que la chaine de Markov générée satisfait les équations de balance détaillée en respect avec la distribution $\pi$.
\begin{equation}
\begin{split}
\pi(i)Q_{ij} & = \pi(i)q(i,j)\alpha(i,j) \\
& = \frac{\pi(i)q(i,j)s(i,j)}{1+\frac{\pi(i) q(i,j)}{\pi(j) q(j,i)}} \\
& = \frac{\pi(i)q(i,j)s(i,j)\pi(j) q(j,i)}{\pi(j) q(j,i)+\pi(i)q(i,j)} \\
& = \frac{\pi(j) q(j,i)s(j,i)}{1+\frac{\pi(j) q(j,i)}{\pi(i) q(i,j)}} \\
& = \pi(j) q(j,i)\alpha(j,i) \\
& = \pi(j)Q_{ji}
\end{split}
\label{eq2}
\end{equation}

\section{Décryptage d'une séquence codée}
\subsubsection*{Question 1}
Il nous est demandé ici de calculer la cardinalité de l'ensemble $\Theta$. L'ensemble $\Theta$ comprends toutes les permutations des caractères utilisés dans la langue anglaise.
Nous avons un total de $N = 40$ symboles et de l'analyse combinatoire nous savons que le nombre de permutations pour des éléments tous différents est égal à la factorielle du nombre d'éléments. Nous obtenons,
$$ \#(\Theta) = N! = 8.16\times 10^{47}$$

















\subsubsection*{Question 2}
%Pas tout a fait sur que cela soit juste, à vérifier et a reformuler
Nous avons un texte non crypté $T'$ et nous cherchons sa vraisemblance donc la probabilité d'observer cette séquence, $Q$ et $\pi_0$ nous sont donné. On compare le premier symbole avec la probabilité de l'observer grâce à $\pi_0$, puis on observe le deuxième symbole de la chaîne. Sachant que l'on a le premier symbole, on regarde quel est la probabilité d'avoir le deuxième symbole par $\pi_0 \textbf{Q} $. De même pour le troisième symbole mais avec $\pi_0\times \textbf{Q}^2$ et ainsi de suite jusqu'au dernier symbole. On multiplie chaque probabilité des symboles pour obtenir la vraisemblance de $T'$. 

%Pas sur que ca soit juste
Pour la vraisemblance d'un texte crypté $D$, cela revient à appliquer le même procédé que précédemment mais en ayant au préalable décrypté le texte par $ T' = \theta^{-1}(D)$ vu la relation biunivoque du cryptage.
%La vraisemblance est la probabilité d'observer un certain texte












\subsubsection*{Question 3}
Nous disposons de 10 codes de déchiffrement possible, qu'on peut choisir de manière équiprobable. Pour chaque code, on va calculer la vraisemblance associée. Ensuite, nous allons utiliser la probabilité a posteriori $p_{\theta|D,\pi_0,Q}(\theta)$ pour chaque code de déchiffrement. Dans cette formule, la distribution de probabilité à priori $p_{\theta}(\theta)$ se factorise car cette dernière peu se sortir de la somme car elle est uniforme.
Le code de déchiffrement aillant une probabilité à posteriori la plus élevée sera le code que nous allons privilégier.

















\subsubsection*{Question 4}
L'algorithme de Metropolis-Hastings est assez simple. Il consiste a prendre un état de départ $x_{0}$ et de tirer, à partir d'une loi de distribution $q$ l'état suivant $y$. On va par après choisir d'accepter ou de rejeter ce dernier avec la valeur alpha, qui est la partie principale de cet algorithme.
Il est intéressant de remarquer que la probabilité à posteriori (\ref{probpost}) peut être simplifiée :

\begin{equation}
\begin{split}
 P_{\theta | D,\pi_{0},Q}(\theta) & = \dfrac{\mathcal{L}(\theta^{-1}(D),\pi_{0},Q)p_{\theta}(\theta)}{\sum_{\theta \in \Theta }{\mathcal{L}(\theta^{-1}(D),\pi_{0},Q)p_{\theta}(\theta)}} \\ & = 
\dfrac{\mathcal{L}(\theta^{-1}(D),\pi_{0},Q)}{\sum_{\theta \in \Theta}{\mathcal{L}(\theta^{-1}(D),\pi_{0},Q)}}
\end{split}
\label{probpost}
\end{equation}

De plus, la variable $\alpha$ (\ref{metropolisalpha}) dans Metropolis-Hastings est également simplifiée en utilisant une loi de distribution symétrique car, du coup, le rapport des deux lois de distribution est égal à $1$. Nous obtenons alors simplement l'algorithme de Metropolis. Nous avons donc utilisé une loi symétrique q pour nous simplifier la tâche.


\begin{equation}
\begin{split}
\alpha & = min\{1,\dfrac{p_{\chi}(y^{(t)})}{p_{\chi}(x^{(t-1)})} \dfrac{q(x^{(t-1)}|y^{(t)})}{q(y^{(t)}|x^{(t-1)})}\} \\ & = min\{1,\dfrac{p_{\chi}(y^{(t)})}{p_{\chi}(x^{(t-1)})}\}
\end{split}
\label{metropolisalpha}
\end{equation}

Dans cette formule, le calcul de la probabilité à posteriori se réduit au simple calcul de la vraisemblance du texte, dont le principe a déjà été abordé à la question 2. En effet, vu qu'on effectue un quotient de deux probabilités à posteriori, la somme de toutes les vraisemblances se factorise automatiquement. Cela vient du fait qu'il s'agit de la somme des vraisemblances de chaque permutation possible de l'ensemble $\theta$, elle reste donc constante pour chaque $\theta \in \Theta$.

En calculant la vraisemblance d'un texte très grand, il se peut qu'on obtienne des erreurs d'arrondi dû aux limites du calcul avec des virgules flottantes. On va procéder au calcul de la vraisemblance par logarithme pour se débarrasser de ces erreurs. Toutefois, nous devons quand même faire attention aux zéros de la matrice de transition $Q$ à cause du rapport $\alpha$. Nous avons donc également choisi d'ajouter une valeur minuscule à chaque élément de la matrice $Q$. Cela laisse les nombres non-nuls quasi inchangés mais permet de transformer un élément nul en un élément infiniment petit mais non nul.













\subsubsection*{Question 5}
La distribution de transition q est une substitution aléatoire c'est-à-dire, une permutation de deux symboles choisis selon une loi uniforme. Chaque permutation a une probabilités de $\frac{1}{n^2}$ ou $n$ est le nombre de symbole, on voit que cette distribution est bien symetrique.
\paragraph{Nombre d'itération}
Nous allons dans un premier lieu étudier le nombre d'itération necessaire pour obtenir une convergence satisfaisante, cela a été testé avec un texte et une clé d'encryption connue. La taille du texte sera testé séparément. Le texte choisi pour effectuer les testes est un roman de George Orwell, 'Animal Farm'. La longueur de l'extrait est de 591 caractères. On définit la précision comme étant le nombre de caractère correctement déchiffré sur le total du nombre de caractère. Le nombre de caractère trouvé est une moyenne sur 10 expériences étant donnée la haute fluctuation des résultats d'un decryptage à l'autre. Les résultats peuvent être observé à la table \ref{PreciItera}. On remarque une faible précision même pour un grand nombre d'itération et cela est du à la taille du texte qui sera discutée ci-dessous. D'une manière générale, la précision augmente avec le nombre d'itération comme attendu. Cependant à partir de 4000-5000 itérations la différence ne se fait plus marquer. Cela semble indiquer qu'il n'est pas nécessaire d'effectuer un nombre d'itération trop important étant donnée le faible gain comparé à l'augmentation du temps d’exécution. Dans ce cas, il est préférable d'effectué plusieurs exécutions du programme jusqu’à obtenir le texte décrypté que d'augmenter de trop le nombre d'itération.
\begin{figure}[!h]
      \centering
      \includegraphics[scale=0.55]{probPost.eps}
       \caption{Évolution de la probabilité à posteriori}
       \label{Probpost}
  \end{figure}
Ce plateau à partir de 5000 itérations peut être d'ailleurs observé par la probabilité à posteriori lors de l'exécution d'un décryptage ceci peut être montré à la figure \ref{Probpost}.
\begin{table}[!h]
\centering
\caption{Précision de décryptage en fonction du nombre d'itération}
\label{PreciItera}
\begin{tabular}{|l|l|}
\hline
 Itérations& Précision (\%) \\ \hline \hline
 1000& 17.0 \\ \hline
 1500& 20.3\\ \hline
 2000& 35.6\\ \hline
 3000& 30.8\\ \hline
 4000& 45.6\\ \hline
 5000& 45.0\\ \hline
 7000& 67.3\\ \hline
 8500& 50.4\\ \hline
\end{tabular}
\end{table}

\paragraph{Longueur du texte}
On remarque que les textes plus court ont plus de mal a être décryptés. Cela vient du fait que, plus il y a de lettres, plus la vraisemblance entre deux séquences de même taille est différente. Ainsi, il est plus facile de converger vers la séquence qui décrypte le texte lorsque ce dernier contient beaucoup de caractères. Nous pouvons aussi avoir l'inverse: un texte trop long pose des problèmes de précision numériques. En effet plus un texte est long plus la vraisemblance pourra être proche de zéros ( ou se rapprochant de moins l'infini en logarithme).
Pour tester l'influence de la longueur du texte à déchiffrer nous allons procéder comme précédemment c'est-à-dire fixé tout autres paramètres et augmenter progressivement la longueur du texte. La précision va être notre critère de comparaison, celle définie précédemment et nous allons effectuer une moyenne sur plusieurs exécutions. Les résultats obtenus sont présentés à la table \ref{longPre}

\begin{table}[!h]
\centering
\caption{Précision de décryptage en fonction de la taille du texte}
\label{longPre}
\begin{tabular}{|l|l|}
\hline
 Nombre de symbole& Précision (\%) \\ \hline \hline
 35& 16.1 \\ \hline
 126& 17.93\\ \hline
 263& 35.5\\ \hline
 314& 44.1\\ \hline
 603& 26.7\\ \hline
 902& 38.4\\ \hline
 1089& 57.74\\ \hline
 1145& 69.2\\ \hline
 1386& 54.2\\ \hline
\end{tabular}
\end{table}
On voit une augmentation de la précision du décryptage avec la taille du texte comme attendu. A partir d'une taille de 1000 caractères, la progression de la précision se fait plus que faiblement et est même non visible vu les fluctuations aléatoires de la précisions. 
\subsubsection*{Question 6}
Nous avons choisi une distribution de proposition q symétrique, pour nous simplifier la tâche et retomber sur l'algorithme de Metropolis. Nous avons finalement décidé de choisir deux lettres aléatoirement dans la séquence y et de les permuter à chaque itération. Nous avons aussi étudié une distribution qui était indépendante de l'état précédent, notamment en prenant aléatoirement une permutation $\theta$ de $\Theta$. Nous avons alors remarqué que puisque d'itération en itération, il n'y a aucun lien, le résultat final ne correspond pas à une progression itérative partant une chaîne initial. Au final, il faudrait, dans le pire des cas, parcourir toutes les permutations de $\Theta$ avant de trouver la séquence qui décrypte le texte fourni. 

Le texte qui nous a été fourni comporte 1107 caractères, ce qui, comme discuté précédemment, est adapté à la convergence de la méthode. Après décryptage par notre programme nous avons obtenus:

\begin{framed}
about noon they saw a pretty snow-white bird sitting on a bough, and singing so sweetly that they stopped to listen. and when he had finished the bird spread his wings and flew before them, and they followed after him until they came to a little house, and the bird perched on the roof, and when they came nearer they saw that the house was built of bread, and roofed with cakes; and the window was of transparent sugar. "we will have some of this," said hansel, "and make a fine meal. i will eat a piece of the roof, grethel, and you can have some of the window-that will taste sweet." so hansel reached up and broke off a bit of the roof, qust to see how it tasted, and grethel stood by the window and gnawed at it. then they heard a thin voice call out from inside, "nibble, nibble, like a mouse, who is nibbling at my house!" and the children answered, "never mind, it is the wind." and they went on eating, never disturbing themselves. hansel, who found that the roof tasted very nice, took down a great piece of it, and grethel pulled out a large round window-pane, and sat her down and began upon it.
\end{framed}
Il est important de noté que certaines exécutions n'était pas exact par rapport à la moyenne, nous avons choisis le texte qui apparaissait le plus fréquemment et qui était le plus vraisemblable.
\newpage
\subsection*{Références}
\begin{enumerate}
\item[$[~1$]] Stephen Connor. \textit{Simulation and Solving Substitution Codes}, mai 2001.
\item[$[~2$]] https://stats.stackexchange.com/posts/47691/revisions 
\end{enumerate}


\end{document}